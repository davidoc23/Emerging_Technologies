{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Third-order letter approximation model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Loading the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and store the content of five books from the \"texts\" folder\n",
    "file_names = [\"book1.txt\", \"book2.txt\", \"book3.txt\", \"book4.txt\", \"book5.txt\"]\n",
    "texts = []\n",
    "\n",
    "# Loop through each file, open it, and append the content to the texts list\n",
    "for file_name in file_names:\n",
    "    with open(f\"texts/{file_name}\", 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        texts.append(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Cleaning the Texts by removing the preambles and postambles of each text in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Function to remove the preamble and postamble of a Project Gutenberg text by identifying the start and end markers. We will use:\n",
    "    - \"START OF THE PROJECT GUTENBERG EBOOK\" as the start marker\n",
    "    - \"END OF THE PROJECT GUTENBERG EBOOK\" as the end marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_preamble_postamble(text):\n",
    "    # Find the start of the main content (after the Project Gutenberg preamble)\n",
    "    start_marker = \"START OF THE PROJECT GUTENBERG EBOOK\"\n",
    "    start_index = text.find(start_marker)\n",
    "    \n",
    "    if start_index != -1:\n",
    "        # Move to the end of the start marker to get to the next line\n",
    "        start_index += len(start_marker)\n",
    "        \n",
    "        # Move to the next line after the start marker\n",
    "        while start_index < len(text) and text[start_index] == ' ':\n",
    "            start_index += 1  # Skip any spaces after the marker\n",
    "        while start_index < len(text) and text[start_index] != '\\n':\n",
    "            start_index += 1  # Skip to the end of the line\n",
    "\n",
    "        # Move to the start of the next line\n",
    "        if start_index < len(text) and text[start_index] == '\\n':\n",
    "            start_index += 1  # Move to the next character after the newline\n",
    "    \n",
    "    # Find the end of the main content (before the Project Gutenberg postamble)\n",
    "    end_marker = \"END OF THE PROJECT GUTENBERG EBOOK\"\n",
    "    end_index = text.find(end_marker)\n",
    "    \n",
    "    if end_index != -1:\n",
    "        # Slice the text up to the start of the end marker\n",
    "        text = text[start_index:end_index].strip()  # Strip whitespace around the result\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Function to:\n",
    "        - Remove the preamble and postamble\n",
    "        - Convert text to uppercase\n",
    "        - Retain only uppercase letters, spaces, and full stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_format_text(text):\n",
    "    # Step 1: Remove preamble and postamble\n",
    "    text = remove_preamble_postamble(text)\n",
    "    \n",
    "    # Step 2: Convert text to uppercase\n",
    "    text = text.upper()\n",
    "    \n",
    "    # Step 3: Create an empty list to store the cleaned characters\n",
    "    cleaned_text = []\n",
    "    \n",
    "    # Step 4: Loop through each character in the text\n",
    "    for char in text:\n",
    "        # Keep the character if it's an uppercase letter, space, or period\n",
    "        if char.isalpha() or char == ' ' or char == '.':\n",
    "            cleaned_text.append(char)\n",
    "    \n",
    "    # Step 5: Join the list of characters back into a string\n",
    "    return ''.join(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to all texts\n",
    "cleaned_texts = [clean_and_format_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the cleaned version of the fourth book to test.txt\n",
    "#with open('test.txt', 'w', encoding='utf-8') as file:\n",
    "#    file.write(cleaned_texts_with_new_end_marker[4])  # Change index as needed\n",
    "#\n",
    "#print(\"Cleaned text has been written to test.txt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Generating Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Function to generate trigrams from the cleaned text.\n",
    "        Each trigram is a sequence of three characters.\n",
    "        Returns a dictionary with trigrams as keys and their counts as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(text):\n",
    "    trigrams = {}\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i + 3]\n",
    "        if trigram in trigrams:\n",
    "            trigrams[trigram] += 1\n",
    "        else:\n",
    "            trigrams[trigram] = 1\n",
    "    return trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Merging Trigram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_trigram_models(models):\n",
    "    \"\"\"\n",
    "        Function to merge multiple trigram models into a single model.\n",
    "        Each model is a dictionary of trigram counts.\n",
    "        Returns a merged dictionary with cumulative trigram counts.\n",
    "    \"\"\"\n",
    "    merged_model = {}\n",
    "    for model in models:\n",
    "        for trigram, count in model.items():\n",
    "            if trigram in merged_model:\n",
    "                merged_model[trigram] += count\n",
    "            else:\n",
    "                merged_model[trigram] = count\n",
    "    return merged_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Analyzing the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        Function to analyze the final trigram model.\n",
    "        Prints the top 10 most common trigrams and their counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_final_model(model):\n",
    "    \n",
    "    sorted_trigrams = sorted(model.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"Top 10 Trigrams and their Counts:\")\n",
    "    for trigram, count in sorted_trigrams:\n",
    "        print(f\"{trigram}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Trigrams and their Counts:\n",
      " TH: 13941\n",
      "THE: 12408\n",
      "HE : 10525\n",
      "AND: 6002\n",
      "ND : 5900\n",
      " AN: 5632\n",
      "ED : 5297\n",
      "ER : 4941\n",
      " OF: 4893\n",
      " TO: 4788\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "# Assume cleaned_texts is a list of cleaned texts from Project Gutenberg\n",
    "trigram_models = [generate_trigrams(text) for text in cleaned_texts]\n",
    "final_model = merge_trigram_models(trigram_models)\n",
    "analyze_final_model(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Generate a string of specified length using the trigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_string_from_trigram_model(model, start_string=\"TH\", length=10000):\n",
    "    generated_string = start_string\n",
    "    current_bigram = start_string[-2:]  # Start with the last two characters\n",
    "    \n",
    "    for _ in range(length - len(start_string)):\n",
    "        # Find trigrams that start with the current bigram\n",
    "        possible_trigrams = {trigram: count for trigram, count in model.items() if trigram.startswith(current_bigram)}\n",
    "        \n",
    "        if not possible_trigrams:  # If no trigrams found, stop generation\n",
    "            break\n",
    "        \n",
    "        total_count = sum(possible_trigrams.values())\n",
    "        \n",
    "        # Prepare weights for the next character selection\n",
    "        next_chars = []\n",
    "        weights = []\n",
    "        \n",
    "        for trigram, count in possible_trigrams.items():\n",
    "            next_char = trigram[-1]  # The third character\n",
    "            next_chars.append(next_char)\n",
    "            weights.append(count)\n",
    "        \n",
    "        # Randomly select the next character based on weights\n",
    "        next_char = random.choices(next_chars, weights=weights)[0]\n",
    "        generated_string += next_char\n",
    "        current_bigram = generated_string[-2:]  # Update the current bigram to the last two characters\n",
    "    \n",
    "    return generated_string\n",
    "\n",
    "# Generate a string of 10,000 characters\n",
    "generated_text = generate_string_from_trigram_model(final_model, start_string=\"TH\", length=10000)\n",
    "\n",
    "# Optionally save the generated text to a file\n",
    "with open('generated_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read the Words List\n",
    "Load the list of valid English words from a file.\n",
    "Returns a set of words for quick lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_list(file_path):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        words = set(word.strip().upper() for word in file.readlines())  # Convert to uppercase for matching\n",
    "    return words\n",
    "\n",
    "# Load the list of English words\n",
    "english_words = load_word_list('words.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Analyze the Generated Text\n",
    "Next, we will analyze the generated text and determine how many of the words present in the generated text are valid English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in generated text: 1717\n",
      "Valid English words found: 533\n",
      "Percentage of valid English words: 31.04%\n"
     ]
    }
   ],
   "source": [
    "def analyze_generated_text(generated_text, valid_words):\n",
    "    # Split the generated text into words\n",
    "    generated_words = generated_text.split()\n",
    "    \n",
    "    # Count the number of valid words\n",
    "    valid_word_count = sum(1 for word in generated_words if word in valid_words)\n",
    "\n",
    "    # Calculate the percentage\n",
    "    total_word_count = len(generated_words)\n",
    "    percentage = (valid_word_count / total_word_count) * 100 if total_word_count > 0 else 0\n",
    "\n",
    "    return valid_word_count, total_word_count, percentage\n",
    "\n",
    "# Analyze the generated text\n",
    "valid_word_count, total_word_count, percentage = analyze_generated_text(generated_text, english_words)\n",
    "\n",
    "print(f\"Total words in generated text: {total_word_count}\")\n",
    "print(f\"Valid English words found: {valid_word_count}\")\n",
    "print(f\"Percentage of valid English words: {percentage:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
